{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "38d1b672",
   "metadata": {},
   "source": [
    "# 01-Ins_Welcome"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "629fbbe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Import Libraries and Dependencies\n",
    "\n",
    "# Import libraries and dependencies\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "### Read in CSV as Pandas DataFrame\n",
    "\n",
    "# Read in CSV data\n",
    "csv_path = Path('../Resources/fb_google_finance.csv')\n",
    "fb_ticker_data = pd.read_csv(csv_path, index_col='Date', parse_dates=True, infer_datetime_format=True)\n",
    "fb_ticker_data.head()\n",
    "\n",
    "### Slice data for Feb 2019\n",
    "\n",
    "# Slice data\n",
    "fb_slice = fb_ticker_data.loc['2019-02-01':'2019-03-01']\n",
    "\n",
    "### Calculate Daily Returns\n",
    "\n",
    "# Calculate daily returns\n",
    "fb_quarter_returns = fb_slice.pct_change()\n",
    "fb_quarter_returns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0eb6f1c2",
   "metadata": {},
   "source": [
    "# 02-Ins_Sorting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31d39476",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Import Libraries and Dependencies\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "### Create DataFrame\n",
    "\n",
    "painting_df = pd.DataFrame(\n",
    "    [\n",
    "        {\"Painting\": \"Mona Lisa (Knockoff)\", \"Price\": 25, \"Popularity\": \"Very Popular\"},\n",
    "        {\"Painting\": \"Van Gogh (Knockoff)\", \"Price\": 20, \"Popularity\": \"Popular\"},\n",
    "        {\"Painting\": \"Starving Artist\", \"Price\": 10, \"Popularity\": \"Average\"},\n",
    "        {\"Painting\": \"Toddler Drawing\", \"Price\": 1, \"Popularity\": \"Not Popular\"},\n",
    "    ]\n",
    ")\n",
    "painting_df\n",
    "\n",
    "### Sort Data\n",
    "\n",
    "# Sort ascending (default)\n",
    "painting_df.sort_values(\"Price\")\n",
    "\n",
    "# Sort descending\n",
    "painting_df.sort_values(\"Price\", ascending=False)\n",
    "\n",
    "### Sorting the index\n",
    "\n",
    "painting_df.sort_index(ascending=False)\n",
    "\n",
    "# Set the price as the index\n",
    "painting_df = painting_df.set_index(\"Price\")\n",
    "painting_df\n",
    "\n",
    "# Sort the index in descending order\n",
    "painting_df.sort_index(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5473946",
   "metadata": {},
   "source": [
    "# 05-Ins_Groupby"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b59365e",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Import Libraries and Dependencies\n",
    "\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "%matplotlib inline\n",
    "\n",
    "### Read in File and Clean Data\n",
    "\n",
    "# Read CSV\n",
    "csv_path = Path('../Resources/crypto_data.csv')\n",
    "crypto_data = pd.read_csv(csv_path, index_col='data_date', parse_dates=True, infer_datetime_format=True)\n",
    "crypto_data\n",
    "\n",
    "# Drop all columns cryptocurrency and data_priceUsd\n",
    "crypto_data = crypto_data.drop(columns=['data_time','timestamp'])\n",
    "\n",
    "# Sort the dates in ascending order\n",
    "crypto_data = crypto_data.sort_index()\n",
    "\n",
    "# Drop missing values\n",
    "crypto_data = crypto_data.dropna()\n",
    "crypto_data.head()\n",
    "\n",
    "### Group DataFrame and perform `count` aggregation\n",
    "\n",
    "# Group by crypto data by cryptocurrency and perform count\n",
    "crypto_data_grp = crypto_data.groupby('cryptocurrency').count()\n",
    "crypto_data_grp\n",
    "\n",
    "### Group DataFrame without aggregate function\n",
    "\n",
    "# Group by crypto data by cryptocurrency\n",
    "crypto_data_grp = crypto_data.groupby('cryptocurrency')\n",
    "crypto_data_grp\n",
    "\n",
    "### Group DataFrame by `cryptocurrency` and calculate the average `data_priceUsd`\n",
    "\n",
    "# Calculate average data_priceUsd for each crypto\n",
    "crypto_data_mean = crypto_data.groupby('cryptocurrency').mean()\n",
    "crypto_data_mean\n",
    "\n",
    "### Group by more than one column and calculate count\n",
    "\n",
    "# Group by more than one column\n",
    "multi_group = crypto_data.groupby(['cryptocurrency','data_priceUsd'])['data_priceUsd'].count()\n",
    "multi_group\n",
    "\n",
    "### Group by more than one column, round price to two decimal places, and calculate count\n",
    "\n",
    "# Group by more than one column after rounding to two decimal places\n",
    "rounded_crypto_data = crypto_data.round({'data_priceUsd': 2})\n",
    "\n",
    "multi_group = rounded_crypto_data.groupby(['cryptocurrency','data_priceUsd'])['data_priceUsd'].count()\n",
    "multi_group\n",
    "\n",
    "### Compare single column grouping to multicolumn grouping\n",
    "\n",
    "# Compare one column group with multiple column group\n",
    "single_group = crypto_data.groupby('cryptocurrency')['data_priceUsd'].count()\n",
    "single_group\n",
    "\n",
    "### Plot grouped data to generate more than one line on the same chart\n",
    "\n",
    "# Plot data_priceUsd for each crypto across time\n",
    "grouped_cryptos = crypto_data.groupby('cryptocurrency')['data_priceUsd'].plot(legend=True)\n",
    "grouped_cryptos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba94b2ab",
   "metadata": {},
   "source": [
    "# 08-Ins_Multi_Indexing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "894991a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Import Libraries and Dependencies\n",
    "\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "### Read in CSV as Pandas DataFrame and Set the Index\n",
    "\n",
    "# Read in data\n",
    "csv_path = Path(\"../Resources/twtr_google_finance.csv\")\n",
    "ticker_data = pd.read_csv(csv_path, parse_dates=True, index_col='Date', infer_datetime_format=True)\n",
    "ticker_data.head()\n",
    "\n",
    "### Display DataFrame Index\n",
    "\n",
    "ticker_data.index\n",
    "\n",
    "### Create Multiple Indices by Grouping By DatetimeIndex `year`, `month`, and `day` with `first` Function\n",
    "\n",
    "# Group by year, month, and day and grab first of each group\n",
    "ticker_data_grp = ticker_data.groupby([ticker_data.index.year, ticker_data.index.month, ticker_data.index.day]).first()\n",
    "ticker_data_grp\n",
    "\n",
    "### Create Multiple Indices by Grouping By DatetimeIndex `year` and `month` with `first` Function\n",
    "\n",
    "# Group by year and month and take the first value of each group\n",
    "ticker_data_grp_2 = ticker_data.groupby([ticker_data.index.year, ticker_data.index.month]).first()\n",
    "ticker_data_grp_2\n",
    "\n",
    "### Create Multiple Indices by Grouping By DatetimeIndex `year` and `month` with `last` Function\n",
    "\n",
    "# Group by year and month and take the last value of each group\n",
    "ticker_data_grp_3 = ticker_data.groupby([ticker_data.index.year, ticker_data.index.month]).last()\n",
    "ticker_data_grp_3\n",
    "\n",
    "### Create Multiple Indices by Grouping By DatetimeIndex `year` and `month` with `mean` Function\n",
    "\n",
    "# Group by year and month and calculate the average of each group\n",
    "ticker_data_grp_4 = ticker_data.groupby([ticker_data.index.year, ticker_data.index.month]).mean()\n",
    "ticker_data_grp_4\n",
    "\n",
    "### Slice Data for 4/12/2019\n",
    "\n",
    "# Slice data for 4/12/2019 from first group\n",
    "ticker_data_slice = ticker_data_grp.loc[2019,4,12]\n",
    "ticker_data_slice\n",
    "\n",
    "### Slice Data For All Days in April 2019\n",
    "\n",
    "# Slice data for April 2019 from first group\n",
    "ticker_data_slice = ticker_data_grp.loc[2019,4]\n",
    "ticker_data_slice"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "380b3751",
   "metadata": {},
   "source": [
    "# 12-Ins_Concat_DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aba10e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Import Libraries and Dependencies\n",
    "\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "### Read in files\n",
    "\n",
    "# Import data\n",
    "france_data_path = Path('../Resources/france_products.csv')\n",
    "uk_data_path = Path('../Resources/uk_products.csv')\n",
    "netherlands_data_path = Path('../Resources/netherlands_products.csv')\n",
    "customer_data_path = Path('../Resources/customer_info.csv')\n",
    "products_data_path = Path('../Resources/products.csv')\n",
    "\n",
    "# Read in data and index by CustomerID\n",
    "france_data = pd.read_csv(france_data_path, index_col='CustomerID')\n",
    "uk_data = pd.read_csv(uk_data_path, index_col='CustomerID')\n",
    "netherlands_data = pd.read_csv(netherlands_data_path, index_col='CustomerID')\n",
    "customer_data = pd.read_csv(customer_data_path, index_col='CustomerID')\n",
    "products_data = pd.read_csv(products_data_path, index_col='CustomerID')\n",
    "\n",
    "### Output sample of data\n",
    "\n",
    "# Show sample of France data\n",
    "france_data.head()\n",
    "\n",
    "# Show sample of UK data\n",
    "uk_data.head()\n",
    "\n",
    "# Show sample of Netherlands data\n",
    "netherlands_data.head()\n",
    "\n",
    "### Concatenate data by rows using `concat` function and `inner` join\n",
    "\n",
    "# Join UK, France, and Netherlands full datasets by axis\n",
    "joined_data_rows = pd.concat([france_data, uk_data, netherlands_data], axis=\"rows\", join=\"inner\")\n",
    "joined_data_rows\n",
    "\n",
    "### Concatenate data by column using `concat` function and `inner` join\n",
    "\n",
    "# Show sample of customer data\n",
    "customer_data.head()\n",
    "\n",
    "# Show sample of product data\n",
    "products_data.head()\n",
    "\n",
    "# Join Customer and products by columns axis\n",
    "joined_data_cols = pd.concat([customer_data, products_data], axis='columns', join='inner')\n",
    "joined_data_cols.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36701b2f",
   "metadata": {},
   "source": [
    "# 15-Ins_Std_Dev_Risk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c78e248c",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Import Libraries and Dependencies\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "%matplotlib inline\n",
    "\n",
    "### Read data\n",
    "\n",
    "file_path = Path(\"../Resources/tech_stocks_closing_value_2018.csv\")\n",
    "tech_stocks = pd.read_csv(file_path, index_col='Date', parse_dates=True)\n",
    "tech_stocks.head()\n",
    "\n",
    "### Calculate Daily Returns\n",
    "\n",
    "# Daily Returns\n",
    "daily_returns = tech_stocks.pct_change()\n",
    "daily_returns.head()\n",
    "\n",
    "### Calcualte standard deviation using `std` function\n",
    "\n",
    "# Daily Standard Deviations\n",
    "daily_std = daily_returns.std()\n",
    "daily_std.head()\n",
    "\n",
    "### Sort standard deviation in desc order\n",
    "\n",
    "# Identify the stock with the most risk\n",
    "daily_std = daily_std.sort_values(ascending=False)\n",
    "daily_std.head()\n",
    "\n",
    "### Calculate the annualized standard deviation\n",
    "\n",
    "# Calculate the annualized standard deviation (252 trading days)\n",
    "annualized_std = daily_std * np.sqrt(252)\n",
    "annualized_std.head()\n",
    "\n",
    "### Plot standard deviation for 3 different portfolios to determine which has the most risk\n",
    "\n",
    "portfolio_a_std = np.random.normal(scale=0.5, size=10000)\n",
    "portfolio_b_std = np.random.normal(scale=1.0, size=10000)\n",
    "portfolio_c_std = np.random.normal(scale=1.5, size=10000)\n",
    "\n",
    "portfolio_std = pd.DataFrame({\n",
    "    \"0.5\": portfolio_a_std,\n",
    "    \"1.0\": portfolio_b_std,\n",
    "    \"1.5\": portfolio_c_std\n",
    "})\n",
    "\n",
    "portfolio_std.plot.hist(stacked=True, bins=100)\n",
    "\n",
    "### Plot standard deviation using box plot\n",
    "\n",
    "# Plot box plot\n",
    "portfolio_std.plot.box()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75c422a1",
   "metadata": {},
   "source": [
    "# 16-Ins_Sharpe_Ratios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e346fdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Import Libraries and Dependencies\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "#!pip install quandl\n",
    "import quandl\n",
    "%matplotlib inline\n",
    "\n",
    "### Read data\n",
    "\n",
    "portfolio_a_path = Path(\"../Resources/tech_stocks_2018_a.csv\")\n",
    "portfolio_b_path = Path(\"../Resources/tech_stocks_2018_b.csv\")\n",
    "risk_free_rate_path= Path(\"../Resources/risk_free_rate.csv\")\n",
    "\n",
    "portfolio_a = pd.read_csv(portfolio_a_path, index_col='Date', parse_dates=True, infer_datetime_format=True)\n",
    "portfolio_b = pd.read_csv(portfolio_b_path, index_col='Date', parse_dates=True, infer_datetime_format=True)\n",
    "risk_free_rate = pd.read_csv(risk_free_rate_path, index_col='Date', parse_dates=True, infer_datetime_format=True)\n",
    "\n",
    "portfolio_a.head()\n",
    "\n",
    "### Calculate Annualized Std Dev\n",
    "\n",
    "# Calculate daily returns\n",
    "portfolio_a_returns = portfolio_a.pct_change().dropna()\n",
    "portfolio_b_returns = portfolio_b.pct_change().dropna()\n",
    "\n",
    "# Concat returns into one DataFrame\n",
    "all_portfolios_returns = pd.concat([portfolio_a_returns, portfolio_b_returns, risk_free_rate], axis='columns', join='inner')\n",
    "all_portfolios_returns.head()\n",
    "\n",
    "# Calculate Sharpe Ratio\n",
    "sharpe_ratios = ((all_portfolios_returns.mean()-all_portfolios_returns['rf_rate'].mean()) * 252) / (all_portfolios_returns.std() * np.sqrt(252))\n",
    "sharpe_ratios\n",
    "\n",
    "### Plot sharpe ratios\n",
    "\n",
    "# Plot sharpe ratios\n",
    "sharpe_ratios.plot(kind=\"bar\", title=\"Sharpe Ratios\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
